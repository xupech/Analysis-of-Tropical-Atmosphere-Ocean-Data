---
title: "A3_Classification"
output: html_document
---

```{r}
library(tidyverse)
library(lubridate)
library(readxl)
library(rsample) 
library(car)
library(ggplot2)
library(caret)
library(dummies)
library(leaps)
library(zoo)
library(BBmisc)
library(rpart)
library(rpart.plot)
library(caret)
library(randomForest)
library(adabag)
```

```{r}
#setwd("~/Desktop")
df1 <- read_csv("new_elnino.csv")
```

```{r}
df = df1%>% filter(buoy %in% c(2, 48))

df_elnino <- df %>% 
  rename(zonal_winds  = `Zonal Winds`,
         meridional_winds = `Meridional Winds`,
         air_temp = `Air Temp`,
         sea_surface_temp = `Sea Surface Temp`) %>% 
  mutate(date = ymd(`New Date`)) %>% 
  select(-Observation,-Latitude, -Longitude, -diff, -`New Date`)

df_elnino$month <- month(df_elnino$date)

predictorsprocessing <- df_elnino%>% 
  select(-buoy, -date, -month)

df_elnino_predictors_squared <- predictorsprocessing^2
colnames(df_elnino_predictors_squared) <- paste(colnames(df_elnino_predictors_squared),"squared",sep = "_")

df_elnino_predictors_int <- as.data.frame(model.matrix( ~.^2, data=predictorsprocessing)) %>% 
  select(-`(Intercept)`) 

temp_2 <- cbind(df_elnino_predictors_int,
                     df_elnino_predictors_squared)

temp_4 <-  data.frame(scale(temp_2))

month <- df_elnino %>% select(month)
buoy <- df_elnino %>% select(buoy)

dfready <- cbind(buoy, month, temp_4)
dfready$month <- as.factor(dfready$month)
df_split <- initial_split(dfready, prop = .70)
df_train <- training(df_split)
df_test  <- testing(df_split)
```
Drop unnecessary columns. Create a variable called month to indicate monthly effect on sea temperature. Create squared and interaction terms for classification and scale all non-categorical variables.
Split data into train and test data by threshold of 70%.

```{r}
default.ct <- rpart(buoy ~ ., data = df_train, method = "class")

prp(default.ct, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

Default tree.

```{r}
default.ct.point.pred.valid <- predict(default.ct,df_test,type = "class")
confusionMatrix(default.ct.point.pred.valid, as.factor(df_test$buoy))
```

Confusion matrix for default tree on test dataset.

```{r}
deeper.ct <- rpart(buoy ~ ., data = df_train, method = "class", cp = 0, minsplit = 1)
```
Deep tree.

```{r}
deeper.ct.point.pred.valid <- predict(deeper.ct,df_test,type = "class")
confusionMatrix(deeper.ct.point.pred.valid, as.factor(df_test$buoy))
```

Confusion matrix for deeper tree on test dataset.

```{r}
cv.ct <- rpart(buoy ~ ., data = df_train, method = "class", 
               cp = 0.00001, minsplit = 5, xval = 5)
# use printcp() to print the table. 
printcp(cv.ct)

pruned.ct <- prune(cv.ct, 
                   cp = cv.ct$cptable[which.min(cv.ct$cptable[,"xerror"]),"CP"])
prp(pruned.ct, type = 1, extra = 1, split.font = 1, varlen = -10) 
```
Built-in cross validation.

```{r}
## random forest
rf <- randomForest(as.factor(buoy) ~ ., data = df_train, ntree = 500, 
                   mtry = 4, nodesize = 5, importance = TRUE)  

## variable importance plot
varImpPlot(rf, type = 1)

## confusion matrix
rf.pred <- predict(rf, df_test)
confusionMatrix(rf.pred, as.factor(df_test$buoy))
```

Random forest and respective confusion matrix.

```{r}
df_train$buoy <- as.factor(df_train$buoy)

set.seed(1)
boost <- boosting(buoy ~ ., data = df_train)
pred <- predict(boost, df_test)
confusionMatrix(as.factor(pred$class), as.factor(df_test$buoy))
```

Boosting and respective confusion matrix. 